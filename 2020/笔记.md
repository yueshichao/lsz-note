# [正则表达式](https://github.com/ziishaned/learn-regex/blob/master/translations/README-cn.md)
- 惰性匹配：?

- 匹配任意字符（除换行符）：*

- 真正的匹配任意字符：[\d\D]*

- 匹配空行：^$\n

- 匹配中文：[\u4e00-\u9fa5]

- 不以Thread、list、web、pool开头的文本: ^\[(Thread|list|web|pool).*

## 举例
- 惰性匹配、正先行断言
字符串：`XXXX,"name":"乐大炮","position":"开发"XXX`
匹配：`乐大炮`  
正则：`"name":"\S+?(?=")`

- 字符串开头、负先行断言(Negative Lookahead)
字符串：
```json
{
"due":"2020-06-19",
"fullBugId":"1154766630001148420",
"handler":"",
}
```
匹配：`不是"fullBugId"开头的行`
正则：`^(?!"fullBug).*` 


# IDEA
## 插件
- maven冲突管理： maven helper

- Intellij IDEA运行报Command line is too long
修改项目下 .idea\workspace.xml，找到标签
<component name="PropertiesComponent">,
在标签里加一行  <property name="dynamic.classpath" value="true" />

# JAVA基础
> https://cyc2018.github.io/CS-Notes/#/  
https://github.com/doocs/advanced-java

- ThreadLocal原理：
  - Thread类拥有 `ThreadLocal.ThreadLocalMap threadLocals = null;` 成员变量，信息都保存在这里
  - `ThreadLocal<T> t = new ThreadLocal<>()` 不会产生任何与线程的关系，但在 `t.set` 时，会将自身，也就是t的引用传入此时线程的 `threadLocals` 里作为key
  - `t.get()` 时也会将自身的hashCode作为key

- HashMap原理：
  - `static class Node<K,V> implements Map.Entry<K, V>` 是HashMap的内部类，（在key冲突不多时）用来存储信息，包括hash、key、value、next四个属性
  - `transient Node<K,V>[] table;` 是HashMap实现的本质——Hash表，数组下标就是key的hashcode，数组内容就是Node对象
> 对象在HashMap里的位置取决于key的hashCode()以及equals()，先比较hashCode，再比较equals  
equals不同，hashcode相同，会被认为是不同的对象。但如果equals相同，hashCode却不同，因比较流程（先hashCode再equals）则会被认为是不同的对象  
所以我们要求重写equals，一定要重写hashCode，即保证equals相同时，hashCode一定相同

> 极端情况下，如果重写对象hashCode恒等于1，HashMap也不会出问题，只是会退化成链表。当同一结点下链表长度大于等于8时，链表转化为红黑树

- ConcurrentHashMap、Hashtable对比
首先HashMap不支持多线程环境，这俩都支持。在并发量较大时，ConcurrentHashMap表现比Hashtable更好，因为Hashtable是在put方法上加锁，而ConcurrentHashMap是在key所在的hash下标那加锁的

- 序列化，实现Serializable接口
 - 自定义序列化内容：`transient`修饰，重写`writeObject`和`readObject`，由ObjectOutputStream通过反射调用

- 动态代理
```java

public class Main {

    public static void main(String[] args) {
        IHello hello = new Hello();
        ProxyHandler proxyHandler = new ProxyHandler(hello);
        IHello proxyHello = (IHello) Proxy.newProxyInstance(hello.getClass().getClassLoader(), hello.getClass().getInterfaces(), proxyHandler);
        proxyHello.sayHello();
    }
}

interface IHello {
    void sayHello();
}

class Hello implements IHello {

    @Override
    public void sayHello() {
        System.out.println("Hello");
    }
}

class ProxyHandler implements InvocationHandler {

    private Object object;

    public ProxyHandler(Object object) {
        this.object = object;
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("Before invoke...");
        method.invoke(object, args);
        System.out.println("After invoke...");
        return null;
    }
}
```

- List.toArray()的类型强转
```java
List<String> collect = Stream.of("1", "2", "3").collect(Collectors.toList());
String[] strings = (String[])collect.toArray();// java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Ljava.lang.String;
System.out.println(Arrays.toString(strings));
```
> 原因有两点：
> 1. 泛型只是在编译期有效，编译成字节码后就没泛型信息了。  
且ArrayList内部使用了`Object[]`来保存数据的，toArray()仅仅是将`Object[]`复制了一份给出
> 2. Java中数组实例是对象（引用类型），也就是说`int[]`是对象，`String[]`是对象，`Object[]`是对象，`String[]`与`Object[]`无继承关系，故不能强转

> ArrayList之所以用`Object[]`来存储数据，而不用`T[]`，是因为创建数组必须在编译时就指定类型

想要强转成功，需要一个一个元素的强转。或调用`toArray(T[] a)`即可;
```java
List<String> collect = Stream.of("1", "2", "3").collect(Collectors.toList());
String[] strings = collect.toArray(new String[collect.size()]);
System.out.println(Arrays.toString(strings));
```

# 并发
- [订单系统的锁](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484989&idx=1&sn=7beaa0db8b29cc8758c7846fe04dfbd2&chksm=ebd7473cdca0ce2a7aea8e6e2a22a5c183b8be3f1cdc93f8d7c3842a560eb5668071cebe5e37&token=948022247&lang=zh_CN#rd)

- [CAS - Compare And Set](https://blog.csdn.net/wufaliang003/article/details/78797203)  
CAS是乐观锁的一种实现
  - 简单的CAS，就是拿到某变量值A，再比较修改：如果修改时A没变，则修改A
  - 基于不重复值的CAS，A是时间戳，或某递增版本号，这样不会有ABA问题
> - 一般cas指令由cpu提供  
> - 简单的CAS会产生ABA问题，比如线程1拿到A，线程2也拿到A，修改为B，又变回A了，此时线程1继续操作，操作的A就不是之前的A了。具体影响需要看业务场景
> - CAS只适用于变量，而不适用于代码块
  



# JVM
- 内存模型：
  - 方法区
  - 堆
  - 栈帧
  - 本地方法栈
  - 程序计数器

- 堆内存参数：初始值`-Xms`， 最大值`-Xmx`

# MySQL
## [聚簇索引](https://www.cnblogs.com/jiawen010/p/11805241.html)
聚簇索引，不是一种索引，而是一种数据存储方式：每张表的主键构造一颗B+树，叶节点存储的就是行数据。在innodb中，表文件就是一个聚簇索引  
- 优点：
  1. 数据访问更快，访问到叶节点即可拿到行数据
  2. 对主键的排序和范围查找非常快
- 缺点：
  1. 插入速度取决于插入顺序，按主键插入最快，否则将会出现页分裂
  2. 更新主键会导致行移动，代价很高
  3. 二级索引需查找两次，第一次找到主键，第二次找到行

## [覆盖索引](https://www.cnblogs.com/happyflyingpig/p/7662881.html)
要查询的列被使用的索引覆盖，不必再回表查

## [联合索引](https://blog.csdn.net/Abysscarry/article/details/80792876)
对a、b、c三列建立索引，相当于a索引，(ab)索引，(abc)索引
`select * from table_name where a = 1` 或者 `... a = 1 and b = 2` 或者 `... a = 1 and b = 2 and c = 3` 联合索引才会生效
`... a = 1 and c = 3` 索引也生效，是因为仅索引a生效了

> 最左前缀原则：区分度（count(distinct a) / count(*)）最高的放在联合索引的最左

# ElasticSearch

# 框架
## Spring
- 对象容器

## Spring Boot
- 约定优于配置
- 内置Servlet容器
- [自动配置](https://blog.csdn.net/weixin_33958366/article/details/87982752)

### ORM框架
#### MyBatis（不完全的ORM框架）
- 直接操作SQL，灵活

#### JPA-Hibernate（完全的ORM框架）
- 使用JPA-Hibernate批量插入时，发现是一条一条insert的。换成JdbcTemplate直接写SQL语句批量插入

- 使用JpaRepository根据指定字段（非主键）删除数据，发现居然先查数据的主键，再根据主键删除数据


# 中间件
## Zookeeper
- 服务于分布式系统，对节点统一管理
- Zookeeper维护一棵树，节点叫做ZNode，分为短暂型和持久型
- C/S模式，客户端监听ZNode节点变化
- 可以做到`统一配置管理`、`统一命名服务`、`分布式锁`、`集群管理`

- [如何实现统一配置](https://blog.csdn.net/u011320740/article/details/78742625)

## 消息中间件
### 基本概念（以kafka为例）
- **Broker**：翻译为代理人，指一个kafka实例，一般一台服务器一个kafka实例
- **Message**：消息实体
- **Topic**：消息的主题（类型），不同服务需要不同的主题，是消息逻辑上的分类
- **Partition**：分片，是一个队列，消息在物理上的分片。
- **Producer**：消息生产者
- **Consumer**：消息消费者
- **ConsumerGroup**：消费者组

#### [kafka](https://blog.csdn.net/weixin_38004638/article/details/90231607)
- Broker
// TODO

- Topic与Partition的关系
Topic是消息在逻辑上的分类，比如Topic可以是device、log，表示设备的消息，或者是日志消息  
一个Topic由若干个Partition组成，一个Patition由一个Broker保存  
kafka仅保证同一Partition下的消息有序，不同Partition间不保证消息的顺序

- ConsumerGroup和Consumer 与 Topic和Partition的关系
一个Partition在同一时刻仅允许一个ConsumerGroup（中的一个Consumer）消费  



## Docker
- systemctl start docker # 启动docker服务
- [常用命令](https://www.cnblogs.com/JMLiu/p/10277482.html)
  - docker exec -it id bash
  - docker logs id -f
  - docker ps -a
  - docker rm id 
  - docker inspect id
  - docker start -i id #交互式的启动容器

- 配置ip转发
  - vi /etc/sysctl.conf # 配置ip转发  
net.ipv4.ip_forward=1
  - systemctl restart network #重启服务
  - sysctl net.ipv4.ip_forward #若返回值为1，表示配置成功

- 修改docker日志大小上限
  - deamon.json

### docker导出镜像
#### save - load命令（用于镜像）
1. docker save -o docker-oracle.tar oracleinanutshell/oracle-xe-11g
2. docker load -i docker-oracle.tar

#### export - import命令（用于容器）
> TODO

### Spring Boot Dockerfile
1. 将spring boot打包成jar，与Dockerfile放在同一个文件夹下
2. 编写Dockerfile
```bash
# Docker image for springboot file run
# VERSION 1.0.0
# Author: lsz
# 基础镜像使用java
FROM java:8
# 作者
MAINTAINER lsz <leshichao@kedacom.com>

# 添加jar进入容器
ADD server.jar app.jar

# 运行jar包
ENTRYPOINT ["java", "-jar", "app.jar"]

# 暴露端口
EXPOSE 8098
```
4. docker build -t spring-boot-demo .
3. docker run -d -p 8098:8098 spring-boot-demo

### docker redis
1. docker pull redis
2. docker run -p 6379:6379 -v $PWD/redis.conf:/etc/redis/redis.conf --privileged=true -d redis:4.0.11 redis-server /etc/redis/redis.conf
> -v参数表示数据卷挂载  
redis几个重要配置参数(/etc/redis/redis.conf)：  
daemonize  no  
bind 0.0.0.0  
protected-mode yes  
requirepass 123456  
databases 20  

> redis常用命令：
config get *
config get bind

### docker tomcat
1. docker pull tomcat
2. docker run -p 8080:8080 -v /data/tomcat/webapps:/usr/local/tomcat/webapps -d tomcat
> 将war包放入webapps文件夹，即可自动运行，访问路径前加项目名

### docker mysql
1. docker pull mysql:5.7.30
2. docker run -p 3306:3306 -v /data/mysql/:/usr


### docker elasticsearch
1. docker pull elasticsearch
2. docker run -d -p 9200:9200 -p 9300:9300 -v /data/conf/es.yml:/usr/share/elasticsearch.yml elasticsearch
> 使用elasticsearch head客户端访问es

[es常见问题](https://www.cnblogs.com/jiu0821/p/6075833.html)
> [elasticsearch max virtual memory areas vm.max_map_count [65530] is too low](https://blog.csdn.net/jiankunking/article/details/65448030)  
vi /etc/sysctl.conf
vm.max_map_count=655360 # 添加配置
sysctl -p # 重启

### docker kibana
1. docker pull kibana:5.6
2. docker run -d --log-driver json-file --log-opt max-size=100m --log-opt max-file=2 --name kibana -p 5601:5601 -v /data/conf/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:5.6

docker run -d -p 5601:5601 -v /data/conf/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:5.6



### docker nginx
1. docker pull nginx
2. docker run -it -p 80:80 -v /data/nginx/nginx.conf:/etc/nginx/nginx.conf -v /data/nginx/conf.d:/etc/nginx/conf.d -v /data/nginx/logs:/var/log/nginx -v /data/nginx/html:/usr/share/nginx/html -d nginx
> 可以先运行一个容器，从中拿出nginx.conf，从容器中拷贝文件命令：docker cp id:/etc/nginx/nginx.conf /data/nginx/  

- 将html文件放入nginx/html目录下，即可浏览器访问到  

- nginx配置转发：  
准备tomcat，IP：192.168.9.108，端口8082，新建webapps/demo/hello.html  
配置nginx目录下conf.d/default.conf文件  
在server节点下新增server配置  
```conf
location /demo/ {
  proxy_pass http://192.168.9.108:8082;
	proxy_set_header Host $host:$server_port;
}
```
访问http://192.168.9.108/demo/hello.html即可访问到tomcat页面

- nginx路径映射规则  
proxy_pass参数末尾带 **/**，就会删除请求URL中的location，  
例如，location配置/demo，  
proxy_pass配置为http://192.168.9.108:8082/，  
tomcat访问地址为http://192.168.9.108:8082/demo/hello.html，  
但通过nginx访问就是http://192.168.9.108/demo/demo/hello.html
另一种就是上面写的，proxy_pass末尾不带 **/**，就不会替换location参数

### docker zookeeper
1. docker run -d -p 2181:2181 zookeeper

### docker kafka
1. docker run -d -eZK_HOSTS=192.168.8.65 kafkamanager/kafka-manager:2.0.0.2

### [docker oracle](https://hub.docker.com/r/oracleinanutshell/oracle-xe-11g)
1. docker pull oracleinanutshell/oracle-xe-11g
2. docker run -d -p 49161:1521 -e ORACLE_ALLOW_REMOTE=true oracleinanutshell/oracle-xe-11g
> hostname: localhost  
port: 49161  
sid: xe  
username: system  
password: oracle  

### [docker weblogic](https://hub.docker.com/r/ismaleiva90/weblogic12)
1. docker pull ismaleiva90/weblogic12
2. docker run -d -p 49163:7001 -p 49164:7002 -p 49165:5556 ismaleiva90/weblogic12
> http://localhost:49163/console
User: weblogic
Pass: welcome1

### [docker activemq](https://hub.docker.com/r/rmohr/activemq)
1. docker pull rmohr/activemq
2. docker run -p 61616:61616 -p 8161:8161 rmohr/activemq

### docker logstash
- docker pull logstash:6.8.10
> 创建配置文件，放在/data/conf/logstash/config/下  
sample.conf
```conf
input {
  stdin { }
}
output {
  stdout { }
}
```
- docker run --name=logstash -p 5044:5044 -p 9600:9600 -it -v /data/conf/logstash/config/:/usr/share/logstash/config/ logstash:6.8.10

# 测试工具
## JMeter
1. 添加线程组，设置线程数、ramp-up时间，循环次数
2. 添加取样器：http请求